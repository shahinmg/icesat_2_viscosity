import earthaccess
import geopandas as gpd
import h5py
import numpy as np
import pandas as pd
import rioxarray 
import shapely.geometry
import tqdm


auth = earthaccess.login()
# get the box
box_path = './amery_ice_shelf_4326.gpkg'
bbox = gpd.read_file(box_path)
minx = bbox.geometry.bounds['minx'][0]
miny = bbox.geometry.bounds['miny'][0]
maxx = bbox.geometry.bounds['maxx'][0]
maxy = bbox.geometry.bounds['maxy'][0]

bbox.geometry.bounds


# Set up spatiotemporal query for ATL07 sea ice product
granules = earthaccess.search_data(
    short_name="ATL06",
    cloud_hosted=True,
    bounding_box=(minx, miny, maxx, maxy),  # xmin, ymin, xmax, ymax
    temporal=("2019-10-01", "2019-12-31"),
)
granules[-1]  # visualize last data granule


%%time
file_obj = earthaccess.open(granules=[granules[0]])[0]
atl_file = h5py.File(name=file_obj, mode="r")
atl_file.keys()


# orientation - 0: backward, 1: forward, 2: transition
orient = atl_file["orbit_info"]["sc_orient"][:]
if orient == 0:
    strong_beams = ["gt1l", "gt2l", "gt3l"]
elif orient == 1:
    strong_beams = ["gt3r", "gt2r", "gt1r"]
strong_beams


for beam in strong_beams:
    print(beam)


atl_file['METADATA'].keys()


atl_file['gt1r']['land_ice_segments']['atl06_quality_summary']


# updated function
meta_data = dict(granules[0].items())
date = meta_data['meta']['native-id'].split('_')[1]
pd_date = gpd.pd.to_datetime(date)

gdf_list = []
for beam in strong_beams:
 
    gdf = gpd.GeoDataFrame(
        data={
            # Key data variables
            "h_li": atl_file[f"{beam}/land_ice_segments/h_li"][:],
            "h_li_sigma": atl_file[f"{beam}/land_ice_segments/h_li_sigma"][:],
            "atl06_quality_summary":atl_file[f"{beam}/land_ice_segments/atl06_quality_summary"][:],
            # Other data variables
            "beam":f'{beam}',
            "date":pd_date
        },
        geometry=gpd.points_from_xy(
            x=atl_file[f"{beam}/land_ice_segments/longitude"][:],
            y=atl_file[f"{beam}/land_ice_segments/latitude"][:],
        ),
        crs="OGC:CRS84",
    )
    
    gdf_list.append(gdf)


gdf_concat = gpd.pd.concat(gdf_list)


gdf_concat[gdf_concat['atl06_quality_summary']==0]


gdf[gdf['atl06_quality_summary']==0]


meta_data = dict(granules[0].items())
date = meta_data['meta']['native-id'].split('_')[1]
pd_date = gpd.pd.to_datetime(date)
gdf = gpd.GeoDataFrame(
    data={
        # Key data variables
        "h_li": atl_file[f"{beam}/land_ice_segments/h_li"][:],
        "h_li_sigma": atl_file[f"{beam}/land_ice_segments/h_li_sigma"][:],
        "n_seg_pulses": atl_file[
            f"{beam}/land_ice_segments/fit_statistics/n_seg_pulses"
        ][:],
        "snr": atl_file[f"{beam}/land_ice_segments/fit_statistics/snr"][:],
        "snr_significance": atl_file[f"{beam}/land_ice_segments/fit_statistics/snr_significance"][:],
        # Other data variables
        "x_atc": atl_file[f"{beam}/land_ice_segments/ground_track/x_atc"][:],
        "y_atc":atl_file[f"{beam}/land_ice_segments/ground_track/y_atc"][:],
        "beam":f'{beam}',
        "date":pd_date
    },
    geometry=gpd.points_from_xy(
        x=atl_file[f"{beam}/land_ice_segments/longitude"][:],
        y=atl_file[f"{beam}/land_ice_segments/latitude"][:],
    ),
    crs="OGC:CRS84",
)


gdf


gdf.to_parquet(path="ATL06_point_cloud_date.gpq", compression="zstd", schema_version="1.1.0")


# atl_file['METADATA'].keys()
meta_data = dict(granules[0].items())
date = meta_data['meta']['native-id'].split('_')[1]
gpd.pd.to_datetime(date)
meta_data['meta']['native-id'][:-3]


def granule2gdf(granule):
    """
    add docstring later
    """

    # read granule with h5py
    file_obj = earthaccess.open(granules=[granule])[0]
    atl_file = h5py.File(name=file_obj, mode="r")

    # get list of strong beams
    # orientation - 0: backward, 1: forward, 2: transition
    orient = atl_file["orbit_info"]["sc_orient"][:]
    if orient == 0:
        strong_beams = ["gt1l", "gt2l", "gt3l"]
    elif orient == 1:
        strong_beams = ["gt3r", "gt2r", "gt1r"]

    
    # get a date from the granule item
    meta_data = dict(granule.items())
    file_name = meta_data['meta']['native-id'][:-3]
    date = meta_data['meta']['native-id'].split('_')[1]
    pd_date = gpd.pd.to_datetime(date)

    # make geodataframe
    gdf_list = []
    for beam in strong_beams:
        gdf = gpd.GeoDataFrame(
            data={
                # Key data variables
                "h_li": atl_file[f"{beam}/land_ice_segments/h_li"][:],
                "h_li_sigma": atl_file[f"{beam}/land_ice_segments/h_li_sigma"][:],
                "atl06_quality_summary":atl_file[f"{beam}/land_ice_segments/atl06_quality_summary"][:],
                # Other data variables
                "beam":f'{beam}',
                "date":pd_date
            },
            geometry=gpd.points_from_xy(
                x=atl_file[f"{beam}/land_ice_segments/longitude"][:],
                y=atl_file[f"{beam}/land_ice_segments/latitude"][:],
            ),
            crs="OGC:CRS84",
        )
        
        gdf_list.append(gdf)

    # concat all strong beams into one geodataframe and filter out possibly bad segments
    gdf_concat = gpd.pd.concat(gdf_list)
    gdf_concat[gdf_concat['atl06_quality_summary']==0]
    
    return gdf, file_name
 


# iterate through granules and save as gpq
for granule in granules[:1]:
    gdf, file_name = granule2gdf(granule)
    gdf.to_parquet(path=f"{file_name}.gpq", compression="zstd", schema_version="1.1.0")


# gdf = gpd.GeoDataFrame(
#     data={
#         # Key data variables
#         "photon_rate": atl_file[f"{beam}/sea_ice_segments/stats/photon_rate"][:],
#         "hist_w": atl_file[f"{beam}/sea_ice_segments/stats/hist_w"][:],
#         "background_r_norm": atl_file[
#             f"{beam}/sea_ice_segments/stats/background_r_norm"
#         ][:],
#         "height_segment_height": atl_file[
#             f"{beam}/sea_ice_segments/heights/height_segment_height"
#         ][:],
#         "height_segment_n_pulse_seg": atl_file[
#             f"{beam}/sea_ice_segments/heights/height_segment_n_pulse_seg"
#         ][:],
#         "hist_mean_h": atl_file[f"{beam}/sea_ice_segments/stats/hist_mean_h"][:],
#         "hist_median_h": atl_file[f"{beam}/sea_ice_segments/stats/hist_median_h"][:],
#         # Other data variables
#         "x_atc": atl_file[f"{beam}/sea_ice_segments/seg_dist_x"][:],
#         "layer_flag": atl_file[f"{beam}/sea_ice_segments/stats/layer_flag"][:],
#         "height_segment_ssh_flag": atl_file[
#             f"{beam}/sea_ice_segments/heights/height_segment_ssh_flag"
#         ][:],
#     },
#     geometry=gpd.points_from_xy(
#         x=atl_file[f"{beam}/sea_ice_segments/longitude"][:],
#         y=atl_file[f"{beam}/sea_ice_segments/latitude"][:],
#     ),
#     crs="OGC:CRS84",
# )
